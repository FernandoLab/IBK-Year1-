---
title: "IBK_08172020"
author: "Ali Bartenslager"
date: "8/17/2020"
output: html_document
---

###trimming at Q30 for IBK_animal_microbiome_submission
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#loading packages in
```{r ,echo=TRUE}
library("import")
library("knitr")
library("BiocStyle")
library("ggplot2")
library("gridExtra")
library("dada2")
library("phyloseq")
library("DECIPHER")
library("ape")
library("phangorn")
library("knitr")
library("BiocStyle")
library("ShortRead")
library("BiocManager")

```

#loading packages
```{r ,echo=TRUE}
knitr::opts_chunk$set(echo = TRUE)
library("knitr")
library("BiocStyle")
.cran_packages <- c("ggplot2", "gridExtra")
.bioc_packages <- c("dada2", "phyloseq", "DECIPHER", "phangorn")
.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
   source("http://bioconductor.org/biocLite.R")
   biocLite(.bioc_packages[!.inst], ask = F)
}
# Load packages into session, and print package version
sapply(c(.cran_packages, .bioc_packages), require, character.only = TRUE)
```

```{r ,echo=TRUE}
fastq_files= "run_q_check"
list.files(fastq_files)
```

#filtering and trimming
```{r ,echo=TRUE}
fnFs <- sort(list.files(fastq_files, pattern="_R1_001.fastq.gz"))
fnRs <- sort(list.files(fastq_files, pattern="_R2_001.fastq.gz"))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sampleNames <- sapply(strsplit(fnFs, "_"), `[`, 1)
# Specify the full path to the fnFs and fnRs
fnFs <- file.path(fastq_files, fnFs)
fnRs <- file.path(fastq_files, fnRs)
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
fnFs[1:3]
fnRs[1:3]
```

#quality plot (foward)
```{r ,echo=TRUE}
plotQualityProfile(fnFs[1:10])
#can change to view more than two plots at a time
```

#quality plot (reverse)
```{r ,echo=TRUE}
#The first two reverse reads:
plotQualityProfile(fnRs[1:5])
```

#trimming and filtering the F/R reads
```{r ,echo=TRUE}
filt_path <- file.path(fastq_files, "filtered") 
if(!file_test("-d", filt_path)) dir.create(filt_path)
filtFs <- file.path(filt_path, paste0(sampleNames, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste0(sampleNames, "_R_filt.fastq.gz"))

#filting the forward and reverse reads
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(235,175),
                    maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
                  compress=TRUE, multithread=TRUE)
out
```

```{r ,echo=TRUE}
saveRDS(out, "out.RDS")
write.table(out, file="out.txt", col.names=T, row.names=T, sep = "\t",quote=F)
```

#Data Statistics after Trimming
```{r ,echo=TRUE}
sum(out[,1]) #total reads in 12928949
sum(out[,2]) #total reads out 11768828
sum(out[,1]) - sum(out[,2]) #reads lost 1160121
sum(out[,2])/sum(out[,1]) # percentage data retained 91%
```


#first set
#Dereplication/error plots
```{r ,echo=TRUE}
#to avoid error, due to very low reads
exists <- file.exists(filtFs) & file.exists(filtRs)
filtFs <- filtFs[exists]
filtRs <- filtRs[exists]
#Dereplication
derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)
# Name the derep-class objects by the sample names
names(derepFs) <- sampleNames
names(derepRs) <- sampleNames

errF <- learnErrors(filtFs, multithread=TRUE)

errR <- learnErrors(filtRs, multithread=TRUE)


plotErrors(errF)
plotErrors(errR)


save(exists, filtFs, filtRs, derepFs, derepRs, errF, errR, file = "runq30.rds")
```


```{r ,echo=TRUE}
dadaFs <- dada(derepFs, err=errF, multithread=TRUE)

dadaRs <- dada(derepRs, err=errR, multithread=TRUE)

dadaFs[[1]]
```

#Construct sequence table and remove chimeras
```{r ,echo=TRUE}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=T)
head(mergers[[1]])
```

```{r ,echo=TRUE}
seqtabAll <- makeSequenceTable(mergers)
dim(seqtabAll)
table(nchar(getSequences(seqtabAll)))
write.table(seqtabAll, file="seqtabAll.txt", col.names=T, row.names=T, sep = "\t",quote=F)

seqtabNoC <- removeBimeraDenovo(seqtabAll)
write.table(seqtabNoC, file="seqtabNoC.txt", col.names=NA, row.names=T, sep = "\t",quote=F)

saveRDS(seqtabNoC, "SEQTAB_nOc.RDS")
SEQTAB <- readRDS("SEQTAB_nOc.RDS")
dim(SEQTAB)
dim(seqtabNoC) #7544 450
t_seqtabNoC= t(seqtabNoC)
dim(t_seqtabNoC)
table(nchar(getSequences(SEQTAB)))
```

#q30 second half of dataset 
```{r ,echo=TRUE}
fastq_files1= "run_q_check2"
list.files(fastq_files1)
```
#filtering and trimming
```{r ,echo=TRUE}
fnFs1 <- sort(list.files(fastq_files1, pattern="_R1_001.fastq.gz"))
fnRs1 <- sort(list.files(fastq_files1, pattern="_R2_001.fastq.gz"))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sampleNames1 <- sapply(strsplit(fnFs1, "_"), `[`, 1)
# Specify the full path to the fnFs and fnRs
fnFs1 <- file.path(fastq_files1, fnFs1)
fnRs1 <- file.path(fastq_files1, fnRs1)
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names1 <- sapply(strsplit(basename(fnFs1), "_"), `[`, 1)
fnFs1[1:3]
fnRs1[1:3]
```
#quality plot (foward)
```{r ,echo=TRUE}
plotQualityProfile(fnFs1[1:10])
#can change to view more than two plots at a time
```

#quality plot (reverse)
```{r ,echo=TRUE}
#The first two reverse reads:
plotQualityProfile(fnRs1[1:5])
```
#trimming and filtering the F/R reads
```{r ,echo=TRUE}
filt_path1 <- file.path(fastq_files1, "filtered") 
if(!file_test("-d", filt_path1)) dir.create(filt_path1)
filtFs1 <- file.path(filt_path1, paste0(sampleNames1, "_F_filt.fastq.gz"))
filtRs1 <- file.path(filt_path1, paste0(sampleNames1, "_R_filt.fastq.gz"))

#filting the forward and reverse reads
out1 <- filterAndTrim(fnFs1, filtFs1, fnRs1, filtRs1, truncLen=c(235,175),
                    maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
                  compress=TRUE, multithread=TRUE)
out1

saveRDS(out1, "out1.RDS")
write.table(out1, file="out1.txt", col.names=T, row.names=T, sep = "\t",quote=F)
```

#Data Statistics after Trimming
```{r ,echo=TRUE}
sum(out1[,1]) #total reads in #16003289
sum(out1[,2]) #total reads out #1382225
sum(out1[,1]) - sum(out1[,2]) #reads lost #2081064
sum(out1[,2])/sum(out1[,1]) # percentage data retained #86.9%
```


#second set
#Dereplication/error plots
```{r ,echo=TRUE}
#to avoid error, due to very low reads
exists1 <- file.exists(filtFs1) & file.exists(filtRs1)
filtFs1 <- filtFs1[exists1]
filtRs1 <- filtRs1[exists1]
#Dereplication
derepFs1 <- derepFastq(filtFs1, verbose=TRUE)
derepRs1 <- derepFastq(filtRs1, verbose=TRUE)
# Name the derep-class objects by the sample names
names(derepFs1) <- sampleNames1
names(derepRs1) <- sampleNames1

errF1 <- learnErrors(filtFs1, multithread=TRUE)

errR1 <- learnErrors(filtRs1, multithread=TRUE)


plotErrors(errF1)
plotErrors(errR1)
save(exists1, filtFs1, filtRs1, derepFs1, derepRs1, errF1, errR1, file = "runq301.rds")
load("run301.rds")
```


```{r ,echo=TRUE}
dadaFs1 <- dada(derepFs1, err=errF1, multithread=TRUE)

dadaRs1 <- dada(derepRs1, err=errR1, multithread=TRUE)

dadaFs1[[1]]
```

#Construct sequence table and remove chimeras
```{r ,echo=TRUE}
mergers1 <- mergePairs(dadaFs1, derepFs1, dadaRs1, derepRs1, verbose=T)
head(mergers1[[1]])
```

```{r ,echo=TRUE}
seqtabAll1 <- makeSequenceTable(mergers1)
dim(seqtabAll1)
table(nchar(getSequences(seqtabAll1)))
write.table(seqtabAll1, file="seqtabAll1.txt", col.names=T, row.names=T, sep = "\t",quote=F)

seqtabNoC1 <- removeBimeraDenovo(seqtabAll1)
write.table(seqtabNoC1, file="seqtabNoC1.txt", col.names=NA, row.names=T, sep = "\t",quote=F)

saveRDS(seqtabNoC1, "SEQTAB_nOc1.RDS")
seqtabNoC1 <- readRDS("SEQTAB_nOc1.RDS")
dim(seqtabNoC1) #456 12050
```

#mergining seqtab files 
```{r ,echo=TRUE}
readRDS("SEQTAB_nOc.RDS")
run1 <- readRDS("SEQTAB_nOc.RDS")

merged_seq_table <- mergeSequenceTables(run1,seqtabNoC1)


saveRDS(merged_seq_table, "merged_seq_table.RDS")
merged_seq_table <- readRDS("merged_seq_table.RDS")
dim(run1) #450 7544
dim(seqtabNoC1) #456 12050
dim(merged_seq_table) # 906 15948
write.table(merged_seq_table, file="seqtabNoCboth.txt", col.names=NA, row.names=T, sep = "\t",quote=F)
```

#Assigning Taxonomy 
```{r ,echo=TRUE}
fastaRef= "./silva_nr_v138_train_set.fa"
taxTab <- assignTaxonomy(merged_seq_table, refFasta = fastaRef, multithread=TRUE)
saveRDS(taxTab, "taxTab.RDS")
readRDS("taxTab.RDS")
taxTab <- readRDS("taxTab.RDS")

taxTa <- addSpecies(taxTab, "silva_species_assignment_v138.fa", verbose=TRUE)
#494 assigned at species level
saveRDS(taxTa, "taxTa.RDS")
taxTa <- readRDS("taxTa.RDS")
write.table(taxTa, file="Analysis_NewMethod2/taxTa_species.txt", col.names=T, row.names=T, sep = "\t")

```

#Extracting the standard goods from R
```{r ,echo=TRUE}
 # giving our seq headers more manageable names (ASV_1, ASV_2...)
asv_seqs <- colnames(merged_seq_table)
asv_headers <- vector(dim(merged_seq_table)[2], mode="character")

for (i in 1:dim(merged_seq_table)[2]) {
  asv_headers[i] <- paste(">ASV", i, sep="_")
}

  # making and writing out a fasta of our final ASV seqs:
asv_fasta <- c(rbind(asv_headers, asv_seqs))
write(asv_fasta, "Analysis_NewMethod2/ASVs.fa")

  # count table:
asv_tab <- t(merged_seq_table)
row.names(asv_tab) <- sub(">", "", asv_headers)
write.table(asv_tab, "Analysis_NewMethod2/ASVs_counts.txt", sep="\t", quote=F)

 # tax table:
asv_tax <- taxTab
row.names(asv_tax) <- sub(">", "", asv_headers)
write.table(asv_tax, "Analysis_NewMethod2/ASVs_taxonomy.txt", sep="\t", quote=F)


```


#bring mapping file in
```{r ,echo=TRUE}
library("phyloseq")
mappingfile_IBKY1 <- read.table("mappingfile_IBK.txt", sep = "\t", header = T)

```


#how to make tree in mothur 
download mothur from www.mothur.org/wiki
mv ~/Downloads/Mothur ~/
#unzip using
tar command
#make sure you have wget downloaded using homebrew
#use wget to get silva-- 
wget http://www.mothur.org/w/images/3/32/Silva.nr_v132.tgz
#unzip- 
tar -zxvf Silva.nr_v132.tgz
#call mothur then you can start aligning
pcr.seqs(fasta=silva.nr_v138.align, start=11894, end=25319, keepdots=F, procesors=8) 
#Output is renamed!

#next rename silva
system(mv silva.nr_v138.pcr.align silva.v4.fasta)

#align
align.seqs(fasta=ASVs08202020.fa, reference=silva.v4.fasta) 

#after aligning must make each ASV have a minimum of 10 characters to be recongized
sed -i -e 's/>/>AAAAAAAAAA/g' mothur/ASVs08202020.align
#also doesnt like ..... must take out
sed -i -e 's/\./-/g' mothur/ASVs08202020.align
#create distances
mothur > dist.seqs(fasta=ASVs08202020.align, processors=2, cutoff=.10, output=phylip)
(will have a new output)
#last step. finalize tree
clearcut(phylip=/Users/alisonbartenslager/mothur/ASVs08202020.phylip.dist) 
(will take awhile)
#change ASV back
sed -i -e 's/AAAAAAAAAA//g' mothur/ASVs08202020.phylip.tre
#move finalized tree back to R working directory before proceeding
mv ~/mothur/ASVs08202020.phylip.tre /Users/alisonbartenslager/Desktop/IBK_animal_microbiome_08172020

#read mapping file/ bring phyloseq tree in (use above to see how to generate tree from mothur)
```{r ,echo=TRUE}
View(mappingfile_IBKY1)
row.names(mappingfile_IBKY1) = mappingfile_IBKY1$Sample_ID
#View(mapping_file)

rownames(mappingfile_IBKY1) = mappingfile_IBKY1$Sample_ID


taxTa <- read.table("taxTa_species.txt",  sep = "\t", header = T, quote = "", stringsAsFactors = F, row.names = 1)
#col.names = NA
taxTaA <- as.matrix(taxTa)

#Use when you cant use below on ps phyloseq merging
ps1 <- phyloseq(otu_table(merged_seq_table, taxa_are_rows = FALSE))
sample_names(ps1) <- paste("sa", sample_names(ps1), sep = "")
ps2 <- merge_phyloseq(ps1, sample_data(mappingfile_IBKY1))
ps3 <- merge_phyloseq(ps2, tax_table(taxTaA))


taxa_names(ps3) <- paste0("ASV_", seq(ntaxa(ps3))) #this command is used when wanting to name ASV 



row.names(mappingfile_IBKY1) <- as.character(mappingfile_IBKY1[, 1])


#import tree from mothur

tree_file <- 'ASVs08202020.phylip.tre'
phylo_tree <- read_tree(tree_file)


##this shows when a "sa" is in front of mapping file. if so, use above starting with ps1 to row.names(mapping_file) <- as. character(mapping_file[, 1])-- need phyloseq object in order to change mapping file to match ps object
taxa_names(ps3) <- paste0("ASV_", seq(ntaxa(ps3)))

ps_IBKY1 <- merge_phyloseq(ps3, phy_tree(phylo_tree))


save(ps_IBKY1, file = "ps_IBKY1.rds")
load("ps_IBKY1.rds")
```

#decontaminating for sequencing contaminates (make sure correct columns are in mapping file)
```{r ,echo=TRUE}
#BiocManager::install("decontam")
library(decontam)

View(ps_IBKY1)
head(sample_data(ps_IBKY1))

sample_data(ps_IBKY1)$is.neg <- sample_data(ps_IBKY1)$Type == "neg_control"
contamdf.prev <- isContaminant(ps_IBKY1, method="prevalence", neg="is.neg", batch = sample_data(ps_IBKY1)$Run, batch.combine = "minimum")
table(contamdf.prev$contaminant)
#View(contamdf.prev)

#keeping the contaminants ( this in order to removal further. can also use to see what family etc these are hitting if wanted )
removal_asv <- which(contamdf.prev$contaminant)
removal_done <- paste0("ASV_", removal_asv)
ps_removal_done <- prune_taxa(removal_done, ps_IBKY1)
taxa_names(ps_IBKY1)
ps_removal_done


#removal of the contaminants 
large_keep <- taxa_names(ps_IBKY1)
good_large_taxa <- large_keep[!(large_keep %in% removal_done)]
good_large_taxa
ps_no_contamination <- prune_taxa(good_large_taxa, ps_IBKY1)
ps_no_contamination
save(ps_no_contamination, file = "ps_no_contamination.rds")
#load("ps_no_contamination.rds")
```

#filtering out Eukaryota
```{r ,echo=TRUE}
remove_kingdoms <- c( "Archaea", "Eukaryota")
ps_filtered_pinkeye <- subset_taxa(ps_IBKY1, !Kingdom %in% remove_kingdoms)
taxa_names(ps_filtered_pinkeye)

write.table(otu_table(ps_filtered_pinkeye, taxa_are_rows = FALSE), "removal_Eukaryota_ASVs_pinkeye.txt", sep = "\t", col.names = NA, row.names = TRUE, quote = FALSE)

save(ps_filtered_pinkeye, file = "ps_filtered_eukaryota_pinkeye.rds")
#load("ps_filtered_eurkaryota_pinkeye.rds")
```

#filtering out neg controls
```{r ,echo=TRUE}
ps_pinkeye_neg <- subset_samples(ps_filtered_pinkeye, Animal_ID != "NEG_CON")
ps_pinkeye_neg

save(ps_pinkeye_neg, file = "ps_pinkeye_neg.rds")
#load("ps_pinkeye_neg.rds")
```

#filtering out cow samples that were not on trial and samples below 3,000 reads
```{r ,echo=TRUE}
min <- min(sample_sums(ps_pinkeye_neg))
reads_per_sample1 <- data.frame(Reads = sample_sums(ps_pinkeye_neg))
reads_per_sample1$Sample_ID <- rownames(reads_per_sample1)
fil= c("sa484", "sa505", "sa865", "sa877", "sa863", "sa528", "sa889", "sa791", "sa874", "sa875", "sa128", "sa848", "sa134", "sa882", "sa887", "sa870", "sa133", "sa873", "sa895", "sa880", "sa866", "sa892", "sa893", "sa79", "sa885", "sa766", "sa136", "sa160", "sa121") 

ps_pinkeye_analyze= prune_samples(!(sample_names(ps_pinkeye_neg) %in% fil), ps_pinkeye_neg)
ps_pinkeye_analyze
min2 <- min(sample_sums(ps_pinkeye_analyze))
reads_per_sample2 <- data.frame(Reads = sample_sums(ps_pinkeye_analyze))
reads_per_sample2$Sample_ID <- rownames(reads_per_sample2)
#View(reads_per_sample2)
save(ps_pinkeye_analyze, file= "ps_pinkeye_analyze.rds")
load("ps_pinkeye_analyze.rds")
```

#prevalance of each ASV Anything less than 1 is removed
```{r ,echo=TRUE}
prevdf_ps= apply(X = otu_table(ps_pinkeye_analyze), 
                       MARGIN = ifelse(taxa_are_rows(ps_pinkeye_analyze), yes = 1, no = 2), 
                       FUN = function(x){sum(x > 0)})
prevdf_ps <- data.frame(Prevalence= prevdf_ps, TotalAbundance=taxa_sums(ps_pinkeye_analyze))
#View(prevdf_ps)

ps_IBK_run <- rownames(prevdf_ps)[prevdf_ps$Prevalence > 1]
ps_IBK_run

ps_IBK_analyze <- prune_taxa(ps_IBK_run, ps_pinkeye_analyze)
ps_IBK_analyze
sum(otu_table(ps_IBK_analyze))/sum(otu_table(ps_pinkeye_analyze)) #99.58% those reads
save(ps_IBK_analyze, file = "ps_IBK_analyze.rds")
load("ps_IBK_analyze.rds")
sum(otu_table(ps_IBK_analyze)) #total reads retained 96% from 23,647,648 reads
```

#Normalize Data set
```{r ,echo=TRUE}
norm_IBK  <-  transform_sample_counts(ps_IBK_analyze, function(x) x / sum(x) )
save(norm_IBK, file= "norm_IBK.rds")
load("norm_IBK.rds")
```

##rarefy 
```{r ,echo=TRUE}

#test <- subset_samples(ps_IBK_analyze, ELISA == "YES")
ps_rarefy <- rarefy_even_depth(ps_IBK_analyze, sample.size = min(sample_sums(ps_IBK_analyze)),
  rngseed = T, replace = TRUE, trimOTUs = TRUE, verbose = TRUE)
Chao1_obser_rarefy= estimate_richness(ps_rarefy, split = TRUE, measures = c("Chao1"))
head(Chao1_obser_rarefy)

obser_rarefy= estimate_richness(ps_rarefy, split = TRUE, measures = c("Observed"))
head(obser_rarefy)
#write.table(obser_rarefy, "a.txt", sep = "\t", row.names = TRUE, col.names = NA, quote = FALSE)
Chao1_obser_rarefy_metadata= merge(mappingfile_IBKY1,Chao1_obser_rarefy, by= "row.names")
head(Chao1_obser_rarefy_metadata)

#rarefy with t test
library("ggpubr")
library("tidyverse")
alpha_meas = c("Observed", "Chao1")
(p <- plot_richness(ps_rarefy, "Time", measures=alpha_meas))
pdf("alpha.pdf")
test <- (p + geom_boxplot(data=p$data, aes(x=Time, y=value, color=NULL), alpha=0.1)) 
pdf("alpha.pdf")
plot(test)
dev.off()


observed_pairwise <- pairwise.wilcox.test(obser_rarefy$Observed, sample_data(ps_rarefy)$Time)
chao1_pairwise <- pairwise.wilcox.test(Chao1_obser_rarefy$Chao1, sample_data(ps_rarefy)$Time)

```


#PCoA weighted
```{r ,echo=TRUE}

ord.nmds.pcoa <- ordinate(norm_IBK, method="PCoA", distance="wunifrac")
beta <-plot_ordination(norm_IBK, ord.nmds.pcoa, axes = c(1,2), color="Time", title="ds_weighted") 

pdf("beta.pdf")
plot(beta)
dev.off()
```

#pairwise permanova 
```{r ,echo=TRUE}
library(vegan)
#19 IBK positive cattle
norm_IBK_Ulcer <- subset_samples(norm_IBK, Ulcer_positive != "NONE")
metadata <- as(sample_data(norm_IBK_Ulcer), "data.frame")

adonis(phyloseq::distance(norm_IBK_Ulcer, method="wunifrac") ~ Treatment + Time + Hide + Sex + Breed + Days_from_birth + Ulcer_positive,
       data = metadata)
#entire data set
metadata <- as(sample_data(norm_IBK), "data.frame")

adonis(phyloseq::distance(norm_IBK, method="wunifrac") ~   Treatment + Time + Hide + Sex + Breed + Days_from_birth + Ulcer_positive,
       data = metadata)

```
#pairwise permanova based on treatment
```{r ,echo=TRUE}
library(vegan)
#Placebo
#View(mappingfile_IBKY1)
norm_IBK_placebo <- subset_samples(norm_IBK, Treatment == "PLACEBO")
metadata <- as(sample_data(norm_IBK_placebo), "data.frame")

adonis(phyloseq::distance(norm_IBK_placebo, method="wunifrac") ~ Time + Hide + Sex + Breed + Days_from_birth + Ulcer_positive,
       data = metadata)

#Commercial 
norm_IBK_commercial <- subset_samples(norm_IBK, Treatment == "COMMERCIAL")
metadata <- as(sample_data(norm_IBK_commercial), "data.frame")

adonis(phyloseq::distance(norm_IBK_commercial, method="wunifrac") ~ Time + Hide + Sex + Breed + Days_from_birth + Ulcer_positive,
       data = metadata)

#Autogenous
norm_IBK_autogenous <- subset_samples(norm_IBK, Treatment == "AUTOGENOUS")
metadata <- as(sample_data(norm_IBK_autogenous), "data.frame")

adonis(phyloseq::distance(norm_IBK_autogenous, method="wunifrac") ~ Time + Hide + Sex + Breed + Days_from_birth + Ulcer_positive,
       data = metadata)

```


#making core for entire data set (ASVs must be present in at least 80% of all samples) 
```{r ,echo=TRUE}

#with non normalized object

prevdf_ps_IBK_ana_orig= apply(X = otu_table(ps_IBK_analyze), 
                       MARGIN = ifelse(taxa_are_rows(ps_IBK_analyze), yes = 1, no = 2), 
                       FUN = function(x){sum(x > 0)})
prevdf_ps_IBK_ana_orig <- data.frame(Prevalence=prevdf_ps_IBK_ana_orig, TotalAbundance=taxa_sums(ps_IBK_analyze))
#View(prevdf_ps_IBK_ana_orig)


core_ps_ana_orig <- rownames(prevdf_ps_IBK_ana_orig)[prevdf_ps_IBK_ana_orig$Prevalence >=711 ]
core_ps_ana_orig

#main core ASVs filtering from normalized data set
name <- c("ASV_2", "ASV_1", "ASV_3")
name_run <- taxa_names(norm_IBK)
name_run_1 <- name_run[(name_run %in% name)]
core_1 <- prune_taxa(name_run_1, norm_IBK)
taxa_names(core_1)
sum(otu_table(core_1))/sum(otu_table(norm_IBK)) ###80% of total reads
save(core_1, file = "core_entire_set.rds")
#load("core_entire_set.rds")
write.table(otu_table(core_1), "core_1.txt", sep = "\t", row.names = TRUE, col.names = NA, quote = FALSE)

```

#making core (time) ##Set criteria of 75% 
```{r ,echo=TRUE}

#Period 1
ps_period1 <- subset_samples(ps_IBK_analyze, Date_swabbed == "5_16_18")
ps_period1

prevdf_ps_period1= apply(X = otu_table(ps_period1), 
                       MARGIN = ifelse(taxa_are_rows(ps_period1), yes = 1, no = 2), 
                       FUN = function(x){sum(x > 0)})
prevdf_ps_period1 <- data.frame(Prevalence= prevdf_ps_period1, TotalAbundance=taxa_sums(ps_period1))
#View(prevdf_ps_period1)

core_ps_period1 <- rownames(prevdf_ps_period1)[prevdf_ps_period1$Prevalence >= 165]
core_ps_period1 #29 ASV

ps_core_period1 <- prune_taxa(core_ps_period1, norm_IBK)
ps_core_period1
sum(otu_table(ps_core_period1))/sum(otu_table(norm_IBK)) #37.8% those ASVs count for this % of total reads
save(ps_core_period1, file = "ps_core_period1.rds")
#load("ps_core_period1.rds")
#Period2
ps_IBK_analyze
ps_period2 <- subset_samples(ps_IBK_analyze, Date_swabbed == "6_6_18")
ps_period2


prevdf_ps_period2= apply(X = otu_table(ps_period2), 
                       MARGIN = ifelse(taxa_are_rows(ps_period2), yes = 1, no = 2), 
                       FUN = function(x){sum(x > 0)})
prevdf_ps_period2 <- data.frame(Prevalence= prevdf_ps_period2, TotalAbundance=taxa_sums(ps_period2))
#View(prevdf_ps_period2)

core_ps_period2 <- rownames(prevdf_ps_period2)[prevdf_ps_period2$Prevalence >=183]
core_ps_period2 #3 asv

ps_core_period2 <- prune_taxa(core_ps_period2, norm_IBK)
ps_core_period2
sum(otu_table(ps_core_period2))/sum(otu_table(norm_IBK)) #78.9% those ASVs count for this % of total reads 
save(ps_core_period2, file = "ps_core_period2.rds")
#load("ps_core_period2.rds")
#Period 3
ps_IBK_analyze
ps_period3 <- subset_samples(ps_IBK_analyze, Date_swabbed == "6_26_18")
ps_period3



prevdf_ps_period3= apply(X = otu_table(ps_period3), 
                       MARGIN = ifelse(taxa_are_rows(ps_period3), yes = 1, no = 2), 
                       FUN = function(x){sum(x > 0)})
prevdf_ps_period3 <- data.frame(Prevalence= prevdf_ps_period3, TotalAbundance=taxa_sums(ps_period3))
#View(prevdf_ps_period3)

core_ps_period3 <- rownames(prevdf_ps_period3)[prevdf_ps_period3$Prevalence >= 151]
core_ps_period3 #5 asv

ps_core_period3 <- prune_taxa(core_ps_period3, norm_IBK)
ps_core_period3
sum(otu_table(ps_core_period3))/sum(otu_table(norm_IBK)) #79.7% those ASVs count for this % of total reads
save(ps_core_period3, file = "ps_core_period3.rds")
#load("ps_core_period3.rds")
#Period 4
ps_IBK_analyze
ps_period4 <- subset_samples(ps_IBK_analyze, Date_swabbed == "10_2_18")
ps_period4


prevdf_ps_period4= apply(X = otu_table(ps_period4), 
                       MARGIN = ifelse(taxa_are_rows(ps_period4), yes = 1, no = 2), 
                       FUN = function(x){sum(x > 0)})
prevdf_ps_period4 <- data.frame(Prevalence= prevdf_ps_period4, TotalAbundance=taxa_sums(ps_period4))
#View(prevdf_ps_period4)

core_ps_period4 <- rownames(prevdf_ps_period4)[prevdf_ps_period4$Prevalence >= 148]
core_ps_period4 #40 asv

ps_core_period4 <- prune_taxa(core_ps_period4, norm_IBK)
ps_core_period4
sum(otu_table(ps_core_period4))/sum(otu_table(norm_IBK)) #83.7% those ASVs count for this % of reads
save(ps_core_period4, file = "ps_core_period4.rds")
#load("ps_core_period4.rds")
write.table(core_ps_period4, "ps_p4.txt")
```



#merging ASVs together for core of each individual time point
```{r ,echo=TRUE}

ASV_periods <- c("ASV_1","ASV_2","ASV_3","ASV_4","ASV_7","ASV_8","ASV_9","ASV_10","ASV_12","ASV_13","ASV_15","ASV_17","ASV_18","ASV_19","ASV_20","ASV_21","ASV_23","ASV_25","ASV_27","ASV_28","ASV_29","ASV_30","ASV_32","ASV_35","ASV_36","ASV_37","ASV_39","ASV_40","ASV_41","ASV_44","ASV_45","ASV_46","ASV_49","ASV_50","ASV_51","ASV_52","ASV_54","ASV_55","ASV_56","ASV_59","ASV_60","ASV_61","ASV_64","ASV_65","ASV_67","ASV_70","ASV_77","ASV_81","ASV_82","ASV_92","ASV_99","ASV_100","ASV_108","ASV_156" )


ASV_periods
allTaxa_IBK_periods <- taxa_names(norm_IBK)
allTaxa1_IBK_periods <- allTaxa_IBK_periods[(allTaxa_IBK_periods %in% ASV_periods)]
core_ASV_IBK_54 <- prune_taxa(allTaxa1_IBK_periods, norm_IBK)
taxa_names(core_ASV_IBK_54)
save(core_ASV_IBK_54, file = "core_ASV_IBK_54.rds")
load("core_ASV_IBK_54.rds")
write.table(otu_table(core_ASV_IBK_54), "core_ASV_IBK_54.txt", sep = "\t", row.names = TRUE, col.names = NA, quote = FALSE)

```

#dendogram for core of all time swabbings
```{r ,echo=TRUE}
library(dendextend)
library(gplots)
hi_plot_deseq_ibk_54 <- phyloseq::distance(core_ASV_IBK_54, method = "wunifrac")
save(hi_plot_deseq_ibk_54, file = "hi_plot_deseq_ibk_54.rds")
load("hi_plot_deseq_ibk_54.rds")

hi_clust_ibk_54 <- hclust(hi_plot_deseq_ibk_54, method = "ward.D2")
plot(hi_clust_ibk_54) 


#made a new mappingfile 
mappingfile_dendrogram_IBK <- read.table("mappingfile_dendrogram_ibk.txt", sep = "\t", header = T, comment.char = "")
#View(mappingfile_dendrogram_IBK)
mappingfile_dendrogram_IBK$Color <- as.character(mappingfile_dendrogram_IBK$Color)

mappingfile_dendrogram_IBK$Sample_ID


wuni_dend_IBK_t <- as.dendrogram(hi_clust_ibk_54, hang=0.1)

SampleID_den_IBK <- labels(wuni_dend_IBK_t)

SampleID_den_IBK 

sort_mapping_dendo_IBK <- mappingfile_dendrogram_IBK[match(SampleID_den_IBK, mappingfile_dendrogram_IBK$Sample_ID),]

#View(sort_mapping_dendo_IBK)

labels_colors(wuni_dend_IBK_t) <- sort_mapping_dendo_IBK$Color
labels_colors(wuni_dend_IBK_t)


labels(wuni_dend_IBK_t) <- sort_mapping_dendo_IBK$Period
wuni_dend_IBK_t <- set(wuni_dend_IBK_t, "labels_cex", 0.5)
labels(wuni_dend_IBK_t)
plot(wuni_dend_IBK_t, ylab="Weighted UniFrac Distance")
```

#heatmap with dendrogram for core of all time swabbings
```{r ,echo=TRUE}
library(gplots)
library(heatmap.plus)
library(RColorBrewer)
core_54 <- otu_table(t(core_ASV_IBK_54))
core_54_df <- as.data.frame(core_54)
dim(core_54_df)

input_input <- as.matrix(core_54_df)
dim(input_input)

#write.table(otu_table(core_54), file = "input_dendrogram.txt", sep = "\t", row.names = TRUE, col.names = NA, quote = FALSE)
#write.table(tax_table(core_ASV_IBK_54), file = "input_taxa_core.txt", sep = "\t", quote = F, row.names = T, col.names = NA)
run_dendrogram <- read.table("input_dendrogram_run.txt",  sep = "\t", header = T, quote = "", stringsAsFactors = F, row.names = 1)
run_dendrogram <- as.matrix(run_dendrogram)

col_labels <- labels(wuni_dend_IBK_t)
#View(col_labels)


col_labels <- col_labels[order(order.dendrogram(wuni_dend_IBK_t))]
#View(col_labels)

col_col <- labels_colors(wuni_dend_IBK_t)
#View(col_col)
col_col <- col_col[order(order.dendrogram(wuni_dend_IBK_t))]
#View(col_col)



heatmap.2(run_dendrogram, scale = "none", col = colorpanel(100, low = "grey", high = "black"), Colv = wuni_dend_IBK_t,
          trace = "none", density = "none", breaks = seq(from=min(range(run_dendrogram)), to=max(range(run_dendrogram)), length.out = 101), symm = F, symkey = F, symbreaks = T, cexRow=0.5, labCol = col_labels, colCol = col_col, ColSideColors = col_col, key = T, margins = c(2,10), dendrogram = "column")

pdf("core_54.pdf")
plot(heatmap.2(run_dendrogram, scale = "none", col = colorpanel(100, low = "grey", high = "black"), Colv = wuni_dend_IBK_t,
          trace = "none", density = "none", breaks = seq(from=min(range(run_dendrogram)), to=max(range(run_dendrogram)), length.out = 101), symm = F, symkey = F, symbreaks = T, cexRow=0.5, labCol = col_labels, colCol = col_col, ColSideColors = col_col, key = T, margins = c(2,10), dendrogram = "column"))
dev.off()
```

#filtering core without (ASV_1, ASV_2, ASV_3) to make dendrogram with heatmap
```{r ,echo=TRUE}

core_51 <- c("ASV_4","ASV_7","ASV_8","ASV_9","ASV_10","ASV_12","ASV_13","ASV_15","ASV_17","ASV_18","ASV_19","ASV_20","ASV_21","ASV_23","ASV_25","ASV_27","ASV_28","ASV_29","ASV_30","ASV_32","ASV_35","ASV_36","ASV_37","ASV_39","ASV_40","ASV_41","ASV_44","ASV_45","ASV_46","ASV_49","ASV_50","ASV_51","ASV_52","ASV_54","ASV_55","ASV_56","ASV_59","ASV_60","ASV_61","ASV_64","ASV_65","ASV_67","ASV_70","ASV_77","ASV_81","ASV_82","ASV_92","ASV_99","ASV_100","ASV_108","ASV_156" )
core_51
allTaxa_IBK_periods_51 <- taxa_names(norm_IBK)
allTaxa1_IBK_periods_51 <- allTaxa_IBK_periods_51[(allTaxa_IBK_periods_51 %in% core_51)]
core_ASV_IBK_periods_51 <- prune_taxa(allTaxa1_IBK_periods_51, norm_IBK)
taxa_names(core_ASV_IBK_periods_51)
save(core_ASV_IBK_periods_51, file = "core_ASV_IBK_periods_51.rds")
#load("core_ASV_IBK_periods_32.rds")

core_51 <- otu_table(t(core_ASV_IBK_periods_51))
core_51_df <- as.data.frame(core_51)
dim(core_51_df)

input51 <- as.matrix(core_51_df)
dim(input51)

#write.table(input51, file = "input_dendrogram_51.txt", sep = "\t", row.names = TRUE, col.names = NA, quote = FALSE)
#write.table(tax_table(core_ASV_IBK_periods_51), file = "input_taxa_core_51.txt", sep = "\t", quote = F, row.names = T, col.names = NA)
run_dendrogram_51 <- read.table("input_dendrogram_51_run.txt",  sep = "\t", header = T, quote = "", stringsAsFactors = F, row.names = 1)
run_dendrogram_51 <- as.matrix(run_dendrogram_51)



col_labels <- labels(wuni_dend_IBK_t)
#View(col_labels)


col_labels <- col_labels[order(order.dendrogram(wuni_dend_IBK_t))]
#View(col_labels)

col_col <- labels_colors(wuni_dend_IBK_t)
#View(col_col)
col_col <- col_col[order(order.dendrogram(wuni_dend_IBK_t))]
#View(col_col)



heatmap.2(run_dendrogram_51, scale = "none", col = colorpanel(100, low = "grey", high = "black"), Colv = wuni_dend_IBK_t,
          trace = "none", density = "none", breaks = seq(from=min(range(0.0)), to=max(range(0.05)), length.out = 101), symm = F, symkey = F, symbreaks = T, labCol = col_labels, colCol = col_col, cexRow = 0.5, ColSideColors = col_col, key = T, dendrogram = "column", margins = c(2, 10.0), scale(0.01))

pdf("core_51.pdf")
plot(heatmap.2(run_dendrogram_51, scale = "none", col = colorpanel(100, low = "grey", high = "black"), Colv = wuni_dend_IBK_t,
          trace = "none", density = "none", breaks = seq(from=min(range(0.0)), to=max(range(0.05)), length.out = 101), symm = F, symkey = F, symbreaks = T, labCol = col_labels, colCol = col_col, cexRow = 0.5, ColSideColors = col_col, key = T, dendrogram = "column", margins = c(2, 10.0), scale(0.01)))
dev.off()

```
#writing out tables for CMM taxa based on time 
```{r ,echo=TRUE}
core_ASV_IBK_54
cmm_p1 <- subset_samples(core_ASV_IBK_54, Date_swabbed == "5_16_18")
cmm_p2 <- subset_samples(core_ASV_IBK_54, Date_swabbed == "6_6_18")
cmm_p3 <- subset_samples(core_ASV_IBK_54, Date_swabbed == "6_26_18")
cmm_p4 <- subset_samples(core_ASV_IBK_54, Date_swabbed == "10_2_18")

write.table(otu_table(cmm_p1), "cmm_p1.txt", sep = "\t", row.names = T, col.names = NA, quote = F)
write.table(otu_table(cmm_p2), "cmm_p2.txt", sep = "\t", row.names = T, col.names = NA, quote = F)
write.table(otu_table(cmm_p3), "cmm_p3.txt", sep = "\t", row.names = T, col.names = NA, quote = F)
write.table(otu_table(cmm_p4), "cmm_p4.txt", sep = "\t", row.names = T, col.names = NA, quote = F)
```
#subsetting samples for Moraxella and Mycoplasma analysis
```{r ,echo=TRUE}
#Moraxella
ps_moraxella <- merge_phyloseq(norm_IBK, sample_data(mappingfile_IBKY1), tax_table(taxTaA))
taxa_names(ps_moraxella)
moraxella_filter <- subset_taxa(ps_moraxella, Genus == "Moraxella")
moraxella_filter

moraxella_filter_p1 <- subset_samples(moraxella_filter)

tax_moraxella <-as(tax_table(moraxella_filter), "matrix")
tax_cols_moraxella <- colnames(tax_moraxella)
tax_moraxella <- as.data.frame(tax_moraxella)
tax_moraxella$taxonomy <- do.call(paste, c(tax_moraxella [tax_cols_moraxella], sep = ";"))
for(co in tax_cols_moraxella) tax_moraxella[co] <- NULL
write.table(otu_table(moraxella_filter), "moraxella.txt", sep = "\t", row.names = TRUE, col.names = NA, quote = FALSE)

prevdf_ps_mo= apply(X = otu_table(moraxella_filter), 
                       MARGIN = ifelse(taxa_are_rows(moraxella_filter), yes = 1, no = 2), 
                       FUN = function(x){sum(x > 0)})
prevdf_ps_mo <- data.frame(Prevalence= prevdf_ps_mo, TotalAbundance=taxa_sums(moraxella_filter))
View(prevdf_ps_mo)

#sum(otu_table(moraxella_filter))/sum(otu_table(ps_IBK_analyze)) ## 1.24%
#sum(otu_table(moraxella_filter))/nsamples(moraxella_filter)

#Mycoplasma
ps_mycoplasma <- merge_phyloseq(norm_IBK, sample_data(mappingfile_IBKY1), tax_table(taxTaA))
taxa_names(ps_mycoplasma)
mycoplasma_filter <- subset_taxa(ps_mycoplasma, Genus == "Mycoplasma")
mycoplasma_filter

prevdf_ps_m= apply(X = otu_table(mycoplasma_filter), 
                       MARGIN = ifelse(taxa_are_rows(mycoplasma_filter), yes = 1, no = 2), 
                       FUN = function(x){sum(x > 0)})
prevdf_ps_m <- data.frame(Prevalence= prevdf_ps_m, TotalAbundance=taxa_sums(mycoplasma_filter))
View(prevdf_ps_m)

#sum(otu_table(mycoplasma_filter))/sum(otu_table(ps_IBK_analyze)) ##29.04%

tax_mycoplasma <-as(tax_table(mycoplasma_filter), "matrix")
tax_cols_mycoplasma <- colnames(tax_mycoplasma)
tax_mycoplasma <- as.data.frame(tax_mycoplasma)
tax_mycoplasma$taxonomy <- do.call(paste, c(tax_mycoplasma [tax_cols_mycoplasma], sep = ";"))
for(co in tax_cols_mycoplasma) tax_mycoplasma[co] <- NULL
write.table(tax_mycoplasma, "tax_mycoplasma.txt", quote = FALSE, col.names = FALSE, sep = "\t")
write.table(otu_table(mycoplasma_filter), "mycoplasma.txt", sep = "\t", row.names = TRUE, col.names = NA, quote = FALSE)

#filtering asvs of only Moraxella and Mycoplasma
filter_ASV_moraxella_mycoplasma <- subset_taxa(ps_mycoplasma, Genus == "Mycoplasma" | Genus == "Moraxella")
filter_ASV_moraxella_mycoplasma


myco_ulcer <- subset_samples(mycoplasma_filter, Ulcer_positive != "NONE")
morax_ulcer <- subset_samples(moraxella_filter, Ulcer_positive != "NONE")
write.table(otu_table(myco_ulcer), "myco_ulcer.txt", sep = "\t", row.names = T, col.names = NA, quote = F )
write.table(otu_table(morax_ulcer), "morax_ulcer.txt", sep = "\t", row.names = T, col.names = NA, quote = F)
```
#PCoA_weighted_Ulcer
```{r ,echo=TRUE}
ps_ulcer_positive <- subset_samples(norm_IBK, infected != "NONE")

ord.nmds.pcoa1 <- ordinate(ps_ulcer_positive, method="PCoA", distance="wunifrac")
ulcer_beta <- plot_ordination(ps_ulcer_positive, ord.nmds.pcoa1, color="infected", title="ulcer_positive_cattle")+
  geom_point(size=7)

pdf("ulcer_beta.pdf")
plot(ulcer_beta)
dev.off()
```
#t test against ulcer (+) cattle with mycoplasma and moraxella
```{r setup, include=FALSE}
morax_ttest <- read.table("morax_ulcer_ttest.txt",  sep = "\t", header = T, quote = "", stringsAsFactors = F, row.names = 1)

observed = morax_ttest$Value
theoretical = 50

t.test(observed,
       mu= theoretical,
       conf.level= 0.95)


morax_ttest <- read.table("myco_ulcer_ttets.txt",  sep = "\t", header = T, quote = "", stringsAsFactors = F, row.names = 1)

observed = morax_ttest$Value
theoretical = 50

t.test(observed,
       mu= theoretical,
       conf.level= 0.95)
```

#diff ASVs for cattle infected with IBK pre and post
```{r ,echo=TRUE}
library(DESeq2)
ps_ulcer <- subset_samples(ps_IBK_analyze, infected != "NONE")

diagdds = phyloseq_to_deseq2(ps_ulcer, ~ Ulcer_positive)
# calculate geometric means prior to estimate size factors
gm_mean = function(x, na.rm=TRUE){
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}
geoMeans = apply(counts(diagdds), 1, gm_mean)
diagdds = estimateSizeFactors(diagdds, geoMeans = geoMeans)
diagdds = DESeq(diagdds, fitType="local")
diagdds = estimateDispersions(diagdds)
diagvst = getVarianceStabilizedData(diagdds)
dim(diagvst)


#Diff ASVs
diagdds = DESeq(diagdds)  #, fitType='local')
res_IBK = results(diagdds)
res_IBK = res_IBK[order(res_IBK$padj, na.last = NA), ]
alpha = 0.05
keepOTUs_IBK_ulcer = rownames(res_IBK[res_IBK$padj > alpha, ])[1:50]
kosticTrimvs_IBK_ulcer = prune_taxa(keepOTUs_IBK, ps_ulcer)
kosticTrimvs_IBK_ulcer
#View(kosticTrimvs_IBK)

#write.table(otu_table(kosticTrimvs_IBK_ulcer), "diff_asvs_ulcer.txt", sep = "\t", row.names = TRUE, col.names = NA, quote = FALSE)
save(kosticTrimvs_IBK_ulcer, file = "kosticTrimvs_ulcer.rds")
#load("kosticTrimvs_ulcer.rds")

ulcer <- c(keepOTUs_IBK_ulcer)

ps_ulcer <- subset_samples(norm_IBK, infected != "NONE")

allTaxa_IBK_ulcer <- taxa_names(ps_ulcer)
allTaxa1_IBK_ulcer <- allTaxa_IBK_ulcer[(allTaxa_IBK_ulcer %in% ulcer)]
diff_ASV_IBK_ulcer <- prune_taxa(allTaxa1_IBK_ulcer, ps_ulcer)
taxa_names(diff_ASV_IBK_ulcer)
save(diff_ASV_IBK_ulcer, file = "diff_ASV_IBK_ulcer.rds")
load("diff_ASV_IBK_ulcer.rds")

#heatmap
plot_heatmap(diff_ASV_IBK_ulcer, sample.label = "infected", sample.order = "Time", taxa.order= "Phylum", taxa.label = "Family")

pdf("ulcer_diff.pdf")
plot(plot_heatmap(diff_ASV_IBK_ulcer, sample.label = "infected", sample.order = "Time", taxa.order= "Phylum", taxa.label = "Family"))
dev.off()

```

#deseq2 diff asvs for each time period by filtering comparison 
```{r ,echo=TRUE}
load("ps_IBK_analyze.rds")
#time 1 and 2
ps_1 <- subset_samples(ps_IBK_analyze, Date_swabbed != "6_26_18")
ps_1_2 <- subset_samples(ps_1, Date_swabbed != "10_2_18")

diagdds = phyloseq_to_deseq2(ps_1_2, ~ Date_swabbed)
# calculate geometric means prior to estimate size factors
gm_mean = function(x, na.rm=TRUE){
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}
geoMeans = apply(counts(diagdds), 1, gm_mean)
diagdds = estimateSizeFactors(diagdds, geoMeans = geoMeans)
diagdds = DESeq(diagdds, fitType="local")
diagdds = estimateDispersions(diagdds)
diagvst = getVarianceStabilizedData(diagdds)
dim(diagvst)

load("ps_IBK_analyze.rds")
#Diff ASVs
diagdds = DESeq(diagdds)  #, fitType='local')
res_IBK = results(diagdds)
res_IBK = res_IBK[order(res_IBK$padj, na.last = NA), ]
alpha = 0.05
keepOTUs25_p12 = rownames(res_IBK[res_IBK$padj > alpha, ])[1:25]
kosticTrimvs25_IBK_p12 = prune_taxa(keepOTUs25_p12, norm_IBK)
kosticTrimvs25_IBK_p12
#View(kosticTrimvs_IBK)
save(kosticTrimvs25_IBK_p12, file = "kosticTrimvs25_p12.rds")
#load("kosticTrimvs_p12.rds")
write.table(otu_table(kosticTrimvs25_IBK_p12), "kosticTrimvs25_IBK_p12.txt", sep = "\t", row.names = TRUE, col.names = NA, quote = FALSE)
plot_heatmap(kosticTrimvs25_IBK_p12, sample.label = "Time", sample.order = "Time", taxa.order= "Phylum", taxa.label = "Family")
```

##period 1 and 3
```{r ,echo= True}
load("ps_IBK_analyze.rds")

ps_1 <- subset_samples(ps_IBK_analyze, Date_swabbed != "6_6_18")
ps_1_3 <- subset_samples(ps_1, Date_swabbed != "10_2_18")

diagdds = phyloseq_to_deseq2(ps_1_3, ~ Date_swabbed)
# calculate geometric means prior to estimate size factors
gm_mean = function(x, na.rm=TRUE){
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}
geoMeans = apply(counts(diagdds), 1, gm_mean)
diagdds = estimateSizeFactors(diagdds, geoMeans = geoMeans)
diagdds = DESeq(diagdds, fitType="local")
diagdds = estimateDispersions(diagdds)
diagvst = getVarianceStabilizedData(diagdds)
dim(diagvst)

load("ps_IBK_analyze.rds")
#Diff ASVs
diagdds = DESeq(diagdds)  #, fitType='local')
res_IBK = results(diagdds)
res_IBK = res_IBK[order(res_IBK$padj, na.last = NA), ]
alpha = 0.05
keepOTUs25_p13 = rownames(res_IBK[res_IBK$padj > alpha, ])[1:25]
kosticTrimvs25_IBK_p13 = prune_taxa(keepOTUs25_p13, norm_IBK)
kosticTrimvs25_IBK_p13
#View(kosticTrimvs_IBK)
save(kosticTrimvs25_IBK_p13, file = "kosticTrimvs25_p13.rds")
#load("kosticTrimvs_p13.rds")
write.table(otu_table(kosticTrimvs25_IBK_p13), "kosticTrimvs25_IBK_p13.txt", sep = "\t", row.names = TRUE, col.names = NA, quote = FALSE)
plot_heatmap(kosticTrimvs25_IBK_p13, sample.label = "Time", sample.order = "Time", taxa.order= "Phylum", taxa.label = "Family")
```

##period 1 and 4
```{r ,echo= True}
load("ps_IBK_analyze.rds")

ps_1 <- subset_samples(ps_IBK_analyze, Date_swabbed != "6_6_18")
ps_1_4 <- subset_samples(ps_1, Date_swabbed != "6_26_18")

diagdds = phyloseq_to_deseq2(ps_1_4, ~ Date_swabbed)
# calculate geometric means prior to estimate size factors
gm_mean = function(x, na.rm=TRUE){
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}
geoMeans = apply(counts(diagdds), 1, gm_mean)
diagdds = estimateSizeFactors(diagdds, geoMeans = geoMeans)
diagdds = DESeq(diagdds, fitType="local")
diagdds = estimateDispersions(diagdds)
diagvst = getVarianceStabilizedData(diagdds)
dim(diagvst)

load("ps_IBK_analyze.rds")
#Diff ASVs
diagdds = DESeq(diagdds)  #, fitType='local')
res_IBK = results(diagdds)
res_IBK = res_IBK[order(res_IBK$padj, na.last = NA), ]
alpha = 0.05
keepOTUs25_p14 = rownames(res_IBK[res_IBK$padj > alpha, ])[1:25]
kosticTrimvs25_IBK_p14 = prune_taxa(keepOTUs25_p14, norm_IBK)
kosticTrimvs25_IBK_p14
#View(kosticTrimvs_IBK)
save(kosticTrimvs25_IBK_p14, file = "kosticTrimvs25_p14.rds")
#load("kosticTrimvs_p14.rds")
write.table(otu_table(kosticTrimvs25_IBK_p14), "kosticTrimvs25_IBK_p14.txt", sep = "\t", row.names = TRUE, col.names = NA, quote = FALSE)
plot_heatmap(kosticTrimvs25_IBK_p14, sample.label = "Time", sample.order = "Time", taxa.order= "Phylum", taxa.label = "Family")
```

#period 2 and 3
```{r ,echo= True}
load("ps_IBK_analyze.rds")

ps_2 <- subset_samples(ps_IBK_analyze, Date_swabbed != "5_16_18")
ps_2_3 <- subset_samples(ps_2, Date_swabbed != "10_2_18")

diagdds = phyloseq_to_deseq2(ps_2_3, ~ Date_swabbed)
# calculate geometric means prior to estimate size factors
gm_mean = function(x, na.rm=TRUE){
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}
geoMeans = apply(counts(diagdds), 1, gm_mean)
diagdds = estimateSizeFactors(diagdds, geoMeans = geoMeans)
diagdds = DESeq(diagdds, fitType="local")
diagdds = estimateDispersions(diagdds)
diagvst = getVarianceStabilizedData(diagdds)
dim(diagvst)

load("ps_IBK_analyze.rds")
#Diff ASVs
diagdds = DESeq(diagdds)  #, fitType='local')
res_IBK = results(diagdds)
res_IBK = res_IBK[order(res_IBK$padj, na.last = NA), ]
alpha = 0.05
keepOTUs25_p23 = rownames(res_IBK[res_IBK$padj > alpha, ])[1:25]
kosticTrimvs25_IBK_p23 = prune_taxa(keepOTUs25_p23, norm_IBK)
kosticTrimvs25_IBK_p23
#View(kosticTrimvs_IBK)
save(kosticTrimvs25_IBK_p23, file = "kosticTrimvs25_p23.rds")
#load("kosticTrimvs_p23.rds")
write.table(otu_table(kosticTrimvs25_IBK_p23), "kosticTrimvs25_IBK_p23.txt", sep = "\t", row.names = TRUE, col.names = NA, quote = FALSE)
plot_heatmap(kosticTrimvs25_IBK_p23, sample.label = "Time", sample.order = "Time", taxa.order= "Phylum", taxa.label = "Family")
```

#period 2 and 4
```{r ,echo= True}
load("ps_IBK_analyze.rds")

ps_2 <- subset_samples(ps_IBK_analyze, Date_swabbed != "5_16_18")
ps_2_4 <- subset_samples(ps_2, Date_swabbed != "6_26_18")

diagdds = phyloseq_to_deseq2(ps_2_4, ~ Date_swabbed)
# calculate geometric means prior to estimate size factors
gm_mean = function(x, na.rm=TRUE){
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}
geoMeans = apply(counts(diagdds), 1, gm_mean)
diagdds = estimateSizeFactors(diagdds, geoMeans = geoMeans)
diagdds = DESeq(diagdds, fitType="local")
diagdds = estimateDispersions(diagdds)
diagvst = getVarianceStabilizedData(diagdds)
dim(diagvst)

load("ps_IBK_analyze.rds")
#Diff ASVs
diagdds = DESeq(diagdds)  #, fitType='local')
res_IBK = results(diagdds)
res_IBK = res_IBK[order(res_IBK$padj, na.last = NA), ]
alpha = 0.05
keepOTUs25_p24 = rownames(res_IBK[res_IBK$padj > alpha, ])[1:25]
kosticTrimvs25_IBK_p24 = prune_taxa(keepOTUs25_p24, norm_IBK)
kosticTrimvs25_IBK_p24
#View(kosticTrimvs_IBK)
save(kosticTrimvs25_IBK_p24, file = "kosticTrimvs25_p24.rds")
#load("kosticTrimvs_p23.rds")
write.table(otu_table(kosticTrimvs25_IBK_p24), "kosticTrimvs25_IBK_p24.txt", sep = "\t", row.names = TRUE, col.names = NA, quote = FALSE)
plot_heatmap(kosticTrimvs25_IBK_p24, sample.label = "Time", sample.order = "Time", taxa.order= "Phylum", taxa.label = "Family")
```
#period 3 and 4
```{r ,echo= True}
load("ps_IBK_analyze.rds")

ps_3 <- subset_samples(ps_IBK_analyze, Date_swabbed != "5_16_18")
ps_3_4 <- subset_samples(ps_2, Date_swabbed != "6_2_18")

diagdds = phyloseq_to_deseq2(ps_3_4, ~ Date_swabbed)
# calculate geometric means prior to estimate size factors
gm_mean = function(x, na.rm=TRUE){
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}
geoMeans = apply(counts(diagdds), 1, gm_mean)
diagdds = estimateSizeFactors(diagdds, geoMeans = geoMeans)
diagdds = DESeq(diagdds, fitType="local")
diagdds = estimateDispersions(diagdds)
diagvst = getVarianceStabilizedData(diagdds)
dim(diagvst)

load("ps_IBK_analyze.rds")
#Diff ASVs
diagdds = DESeq(diagdds)  #, fitType='local')
res_IBK = results(diagdds)
res_IBK = res_IBK[order(res_IBK$padj, na.last = NA), ]
alpha = 0.05
keepOTUs25_p34 = rownames(res_IBK[res_IBK$padj > alpha, ])[1:25]
kosticTrimvs25_IBK_p34 = prune_taxa(keepOTUs25_p34, norm_IBK)
kosticTrimvs25_IBK_p34
#View(kosticTrimvs_IBK)
save(kosticTrimvs25_IBK_p34, file = "kosticTrimvs25_p34.rds")
#load("kosticTrimvs_p34.rds")
write.table(otu_table(kosticTrimvs25_IBK_p34), "kosticTrimvs25_IBK_p34.txt", sep = "\t", row.names = TRUE, col.names = NA, quote = FALSE)
plot_heatmap(kosticTrimvs25_IBK_p34, sample.label = "Time", sample.order = "Time", taxa.order= "Phylum", taxa.label = "Family")
```
#top 50 unique diff asvs merged from time periods 1-4
```{r ,echo= True}
diff_asvs_between_time <- c("ASV_1008","ASV_1013","ASV_1020","ASV_1029","ASV_1045","ASV_1049","ASV_1056","ASV_1063","ASV_1074","ASV_1081","ASV_1083","ASV_1096","ASV_110","ASV_1107","ASV_1113","ASV_1117","ASV_112","ASV_1124","ASV_1128","ASV_1139","ASV_1148","ASV_1158","ASV_116","ASV_1169","ASV_117","ASV_1170","ASV_1174","ASV_1198","ASV_1206","ASV_1217","ASV_1218","ASV_1232","ASV_1234","ASV_1249","ASV_1255","ASV_126","ASV_1267","ASV_1292","ASV_13","ASV_1305","ASV_1308","ASV_1313","ASV_132","ASV_1320","ASV_133","ASV_1332","ASV_134","ASV_1342","ASV_1344","ASV_1347","ASV_1356","ASV_1357","ASV_1361","ASV_1377","ASV_1390","ASV_14","ASV_140","ASV_141","ASV_1420","ASV_144","ASV_1448","ASV_145","ASV_1452","ASV_15","ASV_150","ASV_1506","ASV_1526","ASV_1552","ASV_1569","ASV_157","ASV_159","ASV_160","ASV_164","ASV_1641","ASV_167","ASV_168","ASV_169","ASV_170","ASV_171","ASV_174","ASV_1779","ASV_178","ASV_179","ASV_1792","ASV_182","ASV_190","ASV_2","ASV_207","ASV_21","ASV_22","ASV_225","ASV_226","ASV_231","ASV_245","ASV_246","ASV_248","ASV_259","ASV_261","ASV_266","ASV_27","ASV_270","ASV_275","ASV_285","ASV_286","ASV_289","ASV_29","ASV_298","ASV_301","ASV_305","ASV_309","ASV_312","ASV_315","ASV_319","ASV_322","ASV_324","ASV_327","ASV_333","ASV_339","ASV_340","ASV_343","ASV_350","ASV_354","ASV_362","ASV_37","ASV_374","ASV_386","ASV_398","ASV_403","ASV_404","ASV_405","ASV_409","ASV_413","ASV_418","ASV_419","ASV_423","ASV_424","ASV_426","ASV_427","ASV_449","ASV_452","ASV_453","ASV_454","ASV_456","ASV_458","ASV_46","ASV_462","ASV_47","ASV_474","ASV_476","ASV_485","ASV_49","ASV_492","ASV_503","ASV_511","ASV_52","ASV_520","ASV_523","ASV_526","ASV_527","ASV_529","ASV_544","ASV_545","ASV_559","ASV_562","ASV_565","ASV_572","ASV_577","ASV_58","ASV_584","ASV_587","ASV_59","ASV_593","ASV_60","ASV_600","ASV_603","ASV_612","ASV_615","ASV_617","ASV_618","ASV_623","ASV_625","ASV_641","ASV_645","ASV_6","ASV_650","ASV_655","ASV_658","ASV_659","ASV_660","ASV_661","ASV_670","ASV_680","ASV_681","ASV_683","ASV_69","ASV_695","ASV_697","ASV_11","ASV_734","ASV_739","ASV_74","ASV_741","ASV_743","ASV_745","ASV_749","ASV_754","ASV_765","ASV_771","ASV_773","ASV_774","ASV_775","ASV_776","ASV_78","ASV_783","ASV_784","ASV_785","ASV_787","ASV_79","ASV_792","ASV_793","ASV_799","ASV_803","ASV_816","ASV_817","ASV_818","ASV_827","ASV_829","ASV_834","ASV_846","ASV_847","ASV_853","ASV_86","ASV_863","ASV_864","ASV_866","ASV_867","ASV_874","ASV_88","ASV_881","ASV_882","ASV_883","ASV_899","ASV_9","ASV_900","ASV_904","ASV_907","ASV_912","ASV_915","ASV_919","ASV_928","ASV_929","ASV_930","ASV_935","ASV_94","ASV_943","ASV_951","ASV_961","ASV_963","ASV_985", "ASV_999")
allTaxa_IBK_diff_period <- taxa_names(norm_IBK)
allTaxa1_IBK_diff_period  <- allTaxa_IBK_diff_period [(allTaxa_IBK_diff_period %in% diff_asvs_between_time)]
IBK_diff_period  <- prune_taxa(allTaxa1_IBK_diff_period, norm_IBK)
taxa_names(IBK_diff_period )
save(IBK_diff_period , file = "IBK_diff_period.rds")
#load("IBK_diff_period .rds")
plot_heatmap(IBK_diff_period, sample.label = "Time", sample.order = "Time", taxa.order= "Phylum", taxa.label = "Family")

```

#top 25 unique diff asvs merged from time periods 1-4
```{r ,echo= True}
diff_asvs_between_time25 <- c("ASV_1008","ASV_1013","ASV_1020","ASV_1029","ASV_1045","ASV_1049","ASV_1081","ASV_1083","ASV_1096","ASV_110","ASV_1107","ASV_112","ASV_1158","ASV_1169","ASV_1174","ASV_1198","ASV_1218","ASV_1255","ASV_126","ASV_1292","ASV_13","ASV_1308","ASV_1320","ASV_133","ASV_1332","ASV_1356","ASV_1357","ASV_1361","ASV_1390","ASV_1448","ASV_145","ASV_1452","ASV_150","ASV_1506","ASV_1552","ASV_160","ASV_164","ASV_167","ASV_168","ASV_169","ASV_170","ASV_174","ASV_178","ASV_1792","ASV_182","ASV_2","ASV_207","ASV_21","ASV_22","ASV_225","ASV_245","ASV_246","ASV_248","ASV_261","ASV_266","ASV_27","ASV_275","ASV_285","ASV_286","ASV_29","ASV_301","ASV_305","ASV_315","ASV_324","ASV_354","ASV_37","ASV_386","ASV_398","ASV_403","ASV_413","ASV_418","ASV_419","ASV_427","ASV_449","ASV_453","ASV_458","ASV_47","ASV_474","ASV_476","ASV_485","ASV_492","ASV_52","ASV_520","ASV_523","ASV_526","ASV_527","ASV_559","ASV_562","ASV_565","ASV_572","ASV_577","ASV_58","ASV_584","ASV_587","ASV_59","ASV_593","ASV_65","ASV_617","ASV_618","ASV_655","ASV_659","ASV_660","ASV_661","ASV_681","ASV_69","ASV_695","ASV_697","ASV_711","ASV_739","ASV_74","ASV_741","ASV_743","ASV_754","ASV_765","ASV_771","ASV_773","ASV_774","ASV_776","ASV_784","ASV_785","ASV_787","ASV_792","ASV_803","ASV_817","ASV_829","ASV_847","ASV_853","ASV_86","ASV_863","ASV_874","ASV_88","ASV_881","ASV_882","ASV_883","ASV_904","ASV_907","ASV_915","ASV_94","ASV_961","ASV_999")
allTaxa_IBK_diff_period25 <- taxa_names(norm_IBK)
allTaxa1_IBK_diff_period25  <- allTaxa_IBK_diff_period [(allTaxa_IBK_diff_period25 %in% diff_asvs_between_time25)]
IBK_diff_period25  <- prune_taxa(allTaxa1_IBK_diff_period25, norm_IBK)
taxa_names(IBK_diff_period25 )
save(IBK_diff_period25 , file = "IBK_diff_period25.rds")
load("IBK_diff_period25.rds")

plot_heatmap(IBK_diff_period25, sample.label = "Time", sample.order = "Time", taxa.order= "Phylum", taxa.label = "Order")

```

#plotting those taxa on a pheatmap so that we can visualize the hiarcheal clustering among those taxa. 
```{r ,echo= True}
library("pheatmap")
IBK_otu <- otu_table(t(IBK_diff_period25))
IBK_df_t <- as.data.frame(IBK_otu)
dim(IBK_df_t)
head(IBK_df_t[, 1:20])
#View(IBK_df_t)

#write.table(otu_table(IBK_diff_period25), "test_pheatmap.txt", sep = "\t", row.names = TRUE, col.names = NA, quote = FALSE)
write.table(tax_table(IBK_diff_period25), file = "diff_taxa.txt", sep = "\t", quote = F, row.names = T, col.names = NA)
ibk_pheatmap <- read.table("test_pheatmap.txt",  sep = "\t", header = T, quote = "", stringsAsFactors = F, row.names = 1, check.names = F)
ibk_pheatmap1 <- as.data.frame(t(ibk_pheatmap))
dim(ibk_pheatmap1)


Bac.factors_IBK <- read.csv(file = "sample_names_pheatmap_2.csv", header = TRUE, row.names = 1)
str(Bac.factors_IBK)
Bac.factorsDS_IBK <- select(Bac.factors_IBK,Time)


breaksList = seq(0, .001, by = .00001)

#SampleOrder = order(Bac.factorsDS$Sampling)

pheatmap(ibk_pheatmap1, breaks = breaksList, cluster_cols = F, annotation_col = Bac.factors_IBK,fontsize_row = 4, fontsize_col = 0.5)

pdf("heatmap_diff.pdf")
plot(pheatmap(ibk_pheatmap1, breaks = breaksList, cluster_cols = F, annotation_col = Bac.factors_IBK,fontsize_row = 4, fontsize_col = 0.5))
dev.off()

```

